{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы) с сайтов Superjob и HH. Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:\n",
    "\n",
    "- Наименование вакансии.\n",
    "- Предлагаемую зарплату (отдельно минимальную и максимальную).\n",
    "- Ссылку на саму вакансию.\n",
    "- Сайт, откуда собрана вакансия.\n",
    "\n",
    "По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head Hunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import time\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-2-08bfbaf44333>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-08bfbaf44333>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    salary = salary.getText() \\.replace(u'\\xa0', u'')\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "\n",
    "headers = {\n",
    "    'User-agent': 'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2224.3 Safari/537.36'}\n",
    "\n",
    "\n",
    "def hh(main_link, search_str, n_str):\n",
    "    # n_str - кол-во просматриваемых страниц\n",
    "    html = requests.get(\n",
    "        main_link + '/search/vacancy?clusters=true&enable_snippets=true&text=' + search_str + '&showClusters=true',\n",
    "        headers=headers).text\n",
    "    parsed_html = bs(html, 'lxml')\n",
    "\n",
    "    jobs = []\n",
    "    for i in range(n_str):\n",
    "        jobs_block = parsed_html.find('div', {'class': 'vacancy-serp'})\n",
    "        jobs_list = jobs_block.findChildren(recursive=False)\n",
    "        for job in jobs_list:\n",
    "            job_data = {}\n",
    "            req = job.find('span', {'class': 'g-user-content'})\n",
    "            if req != None:\n",
    "                main_info = req.findChild()\n",
    "                job_name = main_info.getText()\n",
    "                job_link = main_info['href']\n",
    "                salary = job.find('div', {'class': 'vacancy-serp-item__compensation'})\n",
    "\n",
    "                if not salary:\n",
    "                    salary_min = None\n",
    "                    salary_max = None\n",
    "                    salary_currency = None\n",
    "                else:\n",
    "                    salary = salary.getText().replace(u'\\xa0', u'')\n",
    "\n",
    "                    salary = re.split(r'\\s|-', salary)\n",
    "\n",
    "                    if salary[0] == 'до':\n",
    "                        salary_min = None\n",
    "                        salary_max = int(salary[1])\n",
    "                    elif salary[0] == 'от':\n",
    "                        salary_min = int(salary[1])\n",
    "                        salary_max = None\n",
    "                    else:\n",
    "                        salary_min = int(salary[0])\n",
    "                        salary_max = int(salary[1])\n",
    "                    salary_currency = salary[-1]\n",
    "\n",
    "                job_data['name'] = job_name\n",
    "                job_data['salary_min'] = salary_min\n",
    "                job_data['salary_max'] = salary_max\n",
    "                job_data['salary_currency'] = salary_currency\n",
    "                job_data['link'] = job_link\n",
    "                job_data['site'] = main_link\n",
    "                jobs.append(job_data)\n",
    "        time.sleep(random.randint(1, 10))\n",
    "        next_btn_block = parsed_html.find('a', {'class': 'bloko-button HH-Pager-Controls-Next HH-Pager-Control'})\n",
    "        next_btn_link = next_btn_block['href']\n",
    "        html = requests.get(main_link + next_btn_link, headers=headers).text\n",
    "        parsed_html = bs(html, 'lxml')\n",
    "\n",
    "    pprint(jobs)\n",
    "    return jobs\n",
    "\n",
    "\n",
    "search_str = 'Data+science'\n",
    "n_str = 2\n",
    "\n",
    "hh('https://hh.ru', search_str, n_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b2922d26162b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mn_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0msuperjob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.superjob.ru'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-b2922d26162b>\u001b[0m in \u001b[0;36msuperjob\u001b[1;34m(main_link, search_str, n_str)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;34m'link'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmain_link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             })\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mmain_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_link\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'rel'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'next'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "headers = {'User-agent': 'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2224.3 Safari/537.36'}\n",
    "\n",
    "def superjob(main_link, search_str, n_str):\n",
    "    #n_str - кол-во просматриваемых страниц\n",
    "    base_url = main_link +'/vacancy/search/?keywords='+ search_str +'&geo%5Bc%5D%5B0%5D=1'\n",
    "    jobs = []\n",
    "    session = requests.Session()\n",
    "    for i in range(n_str):\n",
    "        request = session.get(base_url, headers = headers)\n",
    "        if request.status_code == 200:\n",
    "            soup = bs(request.content, 'lxml')\n",
    "            divs = soup.find_all('div', {'class':'_3zucV _1fMKr undefined _3tcTB _3SGgo'})\n",
    "            for div in divs:\n",
    "                title = div.find('a').getText()\n",
    "                href = main_link + div.find('a').get('href')\n",
    "                salary = div.find('span', {'class': '_3mfro _2Wp8I PlM3e _2JVkc _2VHxz'})\n",
    "                if salary != None:\n",
    "                    salary = salary.text\n",
    "                    salary = salary.replace(u'\\xa0', u'')\n",
    "                    if '—' in salary:\n",
    "                        salary_min = salary.split('—')[0]\n",
    "                        salary_min = re.sub(r'[^0-9]', '', salary_min)\n",
    "                        salary_max = salary.split('—')[1]\n",
    "                        salary_max = re.sub(r'[^0-9]', '', salary_max)\n",
    "                        salary_min = int(salary_min)\n",
    "                        salary_max = int(salary_max)\n",
    "                    elif 'от' in salary:\n",
    "                        salary_min = salary[2:]\n",
    "                        salary_min = re.sub(r'[^0-9]', '', salary_min)\n",
    "                        salary_min = int(salary_min)\n",
    "                        salary_max = None\n",
    "                    elif 'договорённости' in salary:\n",
    "                        salary_min = None\n",
    "                        salary_max = None\n",
    "                    elif 'до' in salary:\n",
    "                        salary_min = None\n",
    "                        salary_max = salary[2:]\n",
    "                        salary_max = re.sub(r'[^0-9]', '', salary_max)\n",
    "                        salary_max = int(salary_max)\n",
    "                    else:\n",
    "                        salary_min = int(re.sub(r'[^0-9]', '', salary))\n",
    "                        salary_max = int(re.sub(r'[^0-9]', '', salary))\n",
    "                else:\n",
    "                    salary_min = None\n",
    "                    salary_max = None\n",
    "\n",
    "                jobs.append({\n",
    "                    'title': title,\n",
    "                    'href': href,\n",
    "                    'salary_min': salary_min,\n",
    "                    'salary_max': salary_max,\n",
    "                    'link': main_link\n",
    "                })\n",
    "            base_url = main_link + \\\n",
    "                       soup.find('a', {'class': 'icMQ_ _1_Cht _3ze9n f-test-button-dalshe f-test-link-dalshe'})['href']\n",
    "            time.sleep(random.randint(1,10))\n",
    "        else:\n",
    "            print('Ошибка')\n",
    "\n",
    "    pprint(jobs)\n",
    "    return jobs\n",
    "\n",
    "\n",
    "search_str = 'Python'\n",
    "n_str = 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
